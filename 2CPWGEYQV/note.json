{
  "paragraphs": [
    {
      "text": "sc",
      "user": "anonymous",
      "dateUpdated": "Aug 17, 2017 10:16:07 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nres0: org.apache.spark.SparkContext \u003d org.apache.spark.SparkContext@37e1781\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558773_723205029",
      "id": "20170809-170744_552630540",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 17, 2017 10:14:54 AM",
      "dateFinished": "Aug 17, 2017 10:15:32 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark._\nimport org.apache.spark.sql.SQLContext\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.unix_timestamp\nimport org.apache.spark.sql._\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.clustering.KMeans\n",
      "user": "anonymous",
      "dateUpdated": "Aug 17, 2017 10:16:20 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nimport org.apache.spark._\n\nimport org.apache.spark.sql.SQLContext\n\nimport org.apache.spark.sql.types._\n\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.sql.functions.unix_timestamp\n\nimport org.apache.spark.sql._\n\nimport org.apache.spark.ml.feature.VectorAssembler\n\nimport org.apache.spark.ml.clustering.KMeans\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558775_723974527",
      "id": "20170809-170842_1574199277",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 17, 2017 10:16:12 AM",
      "dateFinished": "Aug 17, 2017 10:16:17 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\nimport sqlContext.implicits._\nimport sqlContext._\n\nval schema \u003d StructType(Array(\n     StructField(\"dt\", TimestampType, true),\n     StructField(\"lat\", DoubleType, true),\n     StructField(\"lon\", DoubleType,true),\n     StructField(\"base\", StringType, true)\n))\n\nval df \u003d spark.read.option(\"header\",\"false\")\n        .schema(schema).csv(\"uber-raw-data-sep14.csv\")\n\n\ndf.printSchema()\ndf.show()\n",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:30:51 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nimport sqlContext.implicits._\n\nimport sqlContext._\n\nschema: org.apache.spark.sql.types.StructType \u003d StructType(StructField(dt,TimestampType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(base,StringType,true))\n\ndf: org.apache.spark.sql.DataFrame \u003d [dt: timestamp, lat: double ... 2 more fields]\nroot\n |-- dt: timestamp (nullable \u003d true)\n |-- lat: double (nullable \u003d true)\n |-- lon: double (nullable \u003d true)\n |-- base: string (nullable \u003d true)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Date/Time\n\tat org.apache.xerces.jaxp.datatype.XMLGregorianCalendarImpl$Parser.parseYear(Unknown Source)\n\tat org.apache.xerces.jaxp.datatype.XMLGregorianCalendarImpl$Parser.parse(Unknown Source)\n\tat org.apache.xerces.jaxp.datatype.XMLGregorianCalendarImpl.\u003cinit\u003e(Unknown Source)\n\tat org.apache.xerces.jaxp.datatype.DatatypeFactoryImpl.newXMLGregorianCalendar(Unknown Source)\n\tat javax.xml.bind.DatatypeConverterImpl._parseDateTime(DatatypeConverterImpl.java:422)\n\tat javax.xml.bind.DatatypeConverterImpl.parseDateTime(DatatypeConverterImpl.java:417)\n\tat javax.xml.bind.DatatypeConverter.parseDateTime(DatatypeConverter.java:327)\n\tat org.apache.spark.sql.catalyst.util.DateTimeUtils$.stringToTime(DateTimeUtils.scala:140)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply$mcJ$sp(CSVInferSchema.scala:281)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply(CSVInferSchema.scala:281)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply(CSVInferSchema.scala:281)\n\tat scala.util.Try.getOrElse(Try.scala:79)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$.castTo(CSVInferSchema.scala:278)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:125)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:94)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:167)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:166)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:102)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:166)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:102)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)\n  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n  at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2113)\n  at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2112)\n  at org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2795)\n  at org.apache.spark.sql.Dataset.head(Dataset.scala:2112)\n  at org.apache.spark.sql.Dataset.take(Dataset.scala:2327)\n  at org.apache.spark.sql.Dataset.showString(Dataset.scala:248)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:636)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:595)\n  at org.apache.spark.sql.Dataset.show(Dataset.scala:604)\n  ... 58 elided\nCaused by: java.lang.IllegalArgumentException: Date/Time\n  at org.apache.xerces.jaxp.datatype.XMLGregorianCalendarImpl$Parser.parseYear(Unknown Source)\n  at org.apache.xerces.jaxp.datatype.XMLGregorianCalendarImpl$Parser.parse(Unknown Source)\n  at org.apache.xerces.jaxp.datatype.XMLGregorianCalendarImpl.\u003cinit\u003e(Unknown Source)\n  at org.apache.xerces.jaxp.datatype.DatatypeFactoryImpl.newXMLGregorianCalendar(Unknown Source)\n  at javax.xml.bind.DatatypeConverterImpl._parseDateTime(DatatypeConverterImpl.java:422)\n  at javax.xml.bind.DatatypeConverterImpl.parseDateTime(DatatypeConverterImpl.java:417)\n  at javax.xml.bind.DatatypeConverter.parseDateTime(DatatypeConverter.java:327)\n  at org.apache.spark.sql.catalyst.util.DateTimeUtils$.stringToTime(DateTimeUtils.scala:140)\n  at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply$mcJ$sp(CSVInferSchema.scala:281)\n  at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply(CSVInferSchema.scala:281)\n  at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply(CSVInferSchema.scala:281)\n  at scala.util.Try.getOrElse(Try.scala:79)\n  at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$.castTo(CSVInferSchema.scala:278)\n  at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:125)\n  at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:94)\n  at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:167)\n  at org.apache.spark.sql.execution.datasources.c\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:166)\n  at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n  at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n  at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:102)\n  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:166)\n  at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:102)\n  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n  at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)\n  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)\n  at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)\n  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n  at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n  at org.apache.spark.scheduler.Task.run(Task.scala:99)\n  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n  ... 3 more\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558777_721666033",
      "id": "20170809-182844_431552675",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:30:51 PM",
      "dateFinished": "Aug 16, 2017 10:31:02 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "/*\nimport sqlContext.implicits._\nimport sqlContext._\n\nval schema \u003d StructType(Array(\n     StructField(\"dt\", TimestampType, true),\n     StructField(\"lat\", DoubleType, true),\n     StructField(\"lon\", DoubleType,true),\n     StructField(\"base\", StringType, true)\n))\n\ndf.printSchema()\n\n*/",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1502947558779_722435531",
      "id": "20170810-112548_263866841",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "/*\nval df \u003d spark.read\n        .format(\"org.apache.spark.csv\")\n        .option(\"header\", false)\n        .option(\"dateFormat\", \"MM-dd-yyyy HH:mm:ss\")\n        .schema(schema)\n        .csv(\"uber-raw-data-sep14.csv\")\n        \n*/",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1502947558782_721281285",
      "id": "20170809-181914_772923893",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val df \u003d spark.read\n        .format(\"csv\")\n        .option(\"header\", true)\n        .option(\"InferSchema\", true)\n        .csv(\"uber-raw-data-sep14.csv\")\n        \ndf.dtypes",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:37:31 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ndf: org.apache.spark.sql.DataFrame \u003d [Date/Time: string, Lat: double ... 2 more fields]\n\nres9: Array[(String, String)] \u003d Array((Date/Time,StringType), (Lat,DoubleType), (Lon,DoubleType), (Base,StringType))\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558783_720896536",
      "id": "20170810-114524_1937661452",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:31:35 PM",
      "dateFinished": "Aug 16, 2017 10:31:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.show()",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:37:28 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+-------+--------+------+\n|       Date/Time|    Lat|     Lon|  Base|\n+----------------+-------+--------+------+\n|9/1/2014 0:01:00|40.2201|-74.0021|B02512|\n|9/1/2014 0:01:00|  40.75|-74.0027|B02512|\n|9/1/2014 0:03:00|40.7559|-73.9864|B02512|\n|9/1/2014 0:06:00| 40.745|-73.9889|B02512|\n|9/1/2014 0:11:00|40.8145|-73.9444|B02512|\n|9/1/2014 0:12:00|40.6735|-73.9918|B02512|\n|9/1/2014 0:15:00|40.7471|-73.6472|B02512|\n|9/1/2014 0:16:00|40.6613|-74.2691|B02512|\n|9/1/2014 0:32:00|40.3745|-73.9999|B02512|\n|9/1/2014 0:33:00|40.7633|-73.9773|B02512|\n|9/1/2014 0:33:00|40.7467|-73.6131|B02512|\n|9/1/2014 0:37:00|40.8105|  -73.96|B02512|\n|9/1/2014 0:38:00| 40.679|-74.0111|B02512|\n|9/1/2014 0:39:00|40.4023|-73.9839|B02512|\n|9/1/2014 0:48:00|40.7378|-74.0395|B02512|\n|9/1/2014 0:48:00|40.7214|-73.9884|B02512|\n|9/1/2014 0:49:00|40.8646|-73.9081|B02512|\n|9/1/2014 1:08:00|40.7398|-74.0061|B02512|\n|9/1/2014 1:17:00|40.6793|-74.0116|B02512|\n|9/1/2014 1:19:00|40.7328|-73.9875|B02512|\n+----------------+-------+--------+------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558785_804771796",
      "id": "20170809-173015_1477543069",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:32:24 PM",
      "dateFinished": "Aug 16, 2017 10:32:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// convert column Date/Time from string type to timestamp type\n// reference: https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3741049972324885/3696710289009770/4413065072037724/latest.html\n\nval newdf \u003d df.select($\"Date/Time\", unix_timestamp($\"Date/Time\", \"MM/dd/yyyy HH:mm:ss\").cast(TimestampType).as(\"timestamp\"), $\"Lat\", $\"Lon\", $\"Base\")",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:36:35 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nnewdf: org.apache.spark.sql.DataFrame \u003d [Date/Time: string, timestamp: timestamp ... 3 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558786_805926043",
      "id": "20170810-144415_811282236",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:36:07 PM",
      "dateFinished": "Aug 16, 2017 10:36:08 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "newdf.dtypes",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:35:56 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nres24: Array[(String, String)] \u003d Array((Date/Time,StringType), (timestamp,TimestampType), (Lat,DoubleType), (Lon,DoubleType), (Base,StringType))\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502948144450_321518431",
      "id": "20170816-223544_1610369605",
      "dateCreated": "Aug 16, 2017 10:35:44 PM",
      "dateStarted": "Aug 16, 2017 10:35:56 PM",
      "dateFinished": "Aug 16, 2017 10:35:57 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "newdf.show()",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:37:12 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+--------------------+-------+--------+------+\n|       Date/Time|           timestamp|    Lat|     Lon|  Base|\n+----------------+--------------------+-------+--------+------+\n|9/1/2014 0:01:00|2014-09-01 00:01:...|40.2201|-74.0021|B02512|\n|9/1/2014 0:01:00|2014-09-01 00:01:...|  40.75|-74.0027|B02512|\n|9/1/2014 0:03:00|2014-09-01 00:03:...|40.7559|-73.9864|B02512|\n|9/1/2014 0:06:00|2014-09-01 00:06:...| 40.745|-73.9889|B02512|\n|9/1/2014 0:11:00|2014-09-01 00:11:...|40.8145|-73.9444|B02512|\n|9/1/2014 0:12:00|2014-09-01 00:12:...|40.6735|-73.9918|B02512|\n|9/1/2014 0:15:00|2014-09-01 00:15:...|40.7471|-73.6472|B02512|\n|9/1/2014 0:16:00|2014-09-01 00:16:...|40.6613|-74.2691|B02512|\n|9/1/2014 0:32:00|2014-09-01 00:32:...|40.3745|-73.9999|B02512|\n|9/1/2014 0:33:00|2014-09-01 00:33:...|40.7633|-73.9773|B02512|\n|9/1/2014 0:33:00|2014-09-01 00:33:...|40.7467|-73.6131|B02512|\n|9/1/2014 0:37:00|2014-09-01 00:37:...|40.8105|  -73.96|B02512|\n|9/1/2014 0:38:00|2014-09-01 00:38:...| 40.679|-74.0111|B02512|\n|9/1/2014 0:39:00|2014-09-01 00:39:...|40.4023|-73.9839|B02512|\n|9/1/2014 0:48:00|2014-09-01 00:48:...|40.7378|-74.0395|B02512|\n|9/1/2014 0:48:00|2014-09-01 00:48:...|40.7214|-73.9884|B02512|\n|9/1/2014 0:49:00|2014-09-01 00:49:...|40.8646|-73.9081|B02512|\n|9/1/2014 1:08:00|2014-09-01 01:08:...|40.7398|-74.0061|B02512|\n|9/1/2014 1:17:00|2014-09-01 01:17:...|40.6793|-74.0116|B02512|\n|9/1/2014 1:19:00|2014-09-01 01:19:...|40.7328|-73.9875|B02512|\n+----------------+--------------------+-------+--------+------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558787_805541294",
      "id": "20170810-144810_360446112",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:34:06 PM",
      "dateFinished": "Aug 16, 2017 10:34:08 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val newdf1 \u003d newdf.select($\"Date/Time\", $\"timestamp\", $\"Lat\", $\"Lon\", $\"Base\", unix_timestamp($\"timestamp\", \"E\").as(\"weekday\"))\nnewdf1.show()",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:38:01 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nnewdf1: org.apache.spark.sql.DataFrame \u003d [Date/Time: string, timestamp: timestamp ... 4 more fields]\n+----------------+--------------------+-------+--------+------+----------+\n|       Date/Time|           timestamp|    Lat|     Lon|  Base|   weekday|\n+----------------+--------------------+-------+--------+------+----------+\n|9/1/2014 0:01:00|2014-09-01 00:01:...|40.2201|-74.0021|B02512|1409554860|\n|9/1/2014 0:01:00|2014-09-01 00:01:...|  40.75|-74.0027|B02512|1409554860|\n|9/1/2014 0:03:00|2014-09-01 00:03:...|40.7559|-73.9864|B02512|1409554980|\n|9/1/2014 0:06:00|2014-09-01 00:06:...| 40.745|-73.9889|B02512|1409555160|\n|9/1/2014 0:11:00|2014-09-01 00:11:...|40.8145|-73.9444|B02512|1409555460|\n|9/1/2014 0:12:00|2014-09-01 00:12:...|40.6735|-73.9918|B02512|1409555520|\n|9/1/2014 0:15:00|2014-09-01 00:15:...|40.7471|-73.6472|B02512|1409555700|\n|9/1/2014 0:16:00|2014-09-01 00:16:...|40.6613|-74.2691|B02512|1409555760|\n|9/1/2014 0:32:00|2014-09-01 00:32:...|40.3745|-73.9999|B02512|1409556720|\n|9/1/2014 0:33:00|2014-09-01 00:33:...|40.7633|-73.9773|B02512|1409556780|\n|9/1/2014 0:33:00|2014-09-01 00:33:...|40.7467|-73.6131|B02512|1409556780|\n|9/1/2014 0:37:00|2014-09-01 00:37:...|40.8105|  -73.96|B02512|1409557020|\n|9/1/2014 0:38:00|2014-09-01 00:38:...| 40.679|-74.0111|B02512|1409557080|\n|9/1/2014 0:39:00|2014-09-01 00:39:...|40.4023|-73.9839|B02512|1409557140|\n|9/1/2014 0:48:00|2014-09-01 00:48:...|40.7378|-74.0395|B02512|1409557680|\n|9/1/2014 0:48:00|2014-09-01 00:48:...|40.7214|-73.9884|B02512|1409557680|\n|9/1/2014 0:49:00|2014-09-01 00:49:...|40.8646|-73.9081|B02512|1409557740|\n|9/1/2014 1:08:00|2014-09-01 01:08:...|40.7398|-74.0061|B02512|1409558880|\n|9/1/2014 1:17:00|2014-09-01 01:17:...|40.6793|-74.0116|B02512|1409559420|\n|9/1/2014 1:19:00|2014-09-01 01:19:...|40.7328|-73.9875|B02512|1409559540|\n+----------------+--------------------+-------+--------+------+----------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558789_803232800",
      "id": "20170810-155349_780557568",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:37:56 PM",
      "dateFinished": "Aug 16, 2017 10:37:58 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "/*\n// split date and time into separate columns\nimport org.apache.spark.sql.functions.split\n\nval uber \u003d df.select(\n  split($\"Date/Time\", \" \")(0).alias(\"date\"),\n  split($\"Date/Time\", \" \")(1).alias(\"time\"),\n  $\"Lat\",$\"Lon\",$\"Base\"\n)\n\n//reference : https://stackoverflow.com/questions/44750844/how-to-split-column-to-two-different-columns\n\nuber.show()\n*/\n",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1502947558790_804387047",
      "id": "20170809-224501_520322100",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// define feature columns to put in the feature vectors\nval featureCols \u003d Array(\"Lat\",\"Lon\")\n\n// set the input column names\nval assembler \u003d new VectorAssembler().setInputCols(featureCols).setOutputCol(\"features\")\n\n// return a dataframe with all of the feature columns in a vector column\nval df2 \u003d assembler.transform(newdf)",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:38:11 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nfeatureCols: Array[String] \u003d Array(Lat, Lon)\n\nassembler: org.apache.spark.ml.feature.VectorAssembler \u003d vecAssembler_f74a4c4a8860\n\ndf2: org.apache.spark.sql.DataFrame \u003d [Date/Time: string, timestamp: timestamp ... 4 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558792_802078554",
      "id": "20170809-173033_1997534290",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:36:46 PM",
      "dateFinished": "Aug 16, 2017 10:36:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df2.show()",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:38:18 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+--------------------+-------+--------+------+------------------+\n|       Date/Time|           timestamp|    Lat|     Lon|  Base|          features|\n+----------------+--------------------+-------+--------+------+------------------+\n|9/1/2014 0:01:00|2014-09-01 00:01:...|40.2201|-74.0021|B02512|[40.2201,-74.0021]|\n|9/1/2014 0:01:00|2014-09-01 00:01:...|  40.75|-74.0027|B02512|  [40.75,-74.0027]|\n|9/1/2014 0:03:00|2014-09-01 00:03:...|40.7559|-73.9864|B02512|[40.7559,-73.9864]|\n|9/1/2014 0:06:00|2014-09-01 00:06:...| 40.745|-73.9889|B02512| [40.745,-73.9889]|\n|9/1/2014 0:11:00|2014-09-01 00:11:...|40.8145|-73.9444|B02512|[40.8145,-73.9444]|\n|9/1/2014 0:12:00|2014-09-01 00:12:...|40.6735|-73.9918|B02512|[40.6735,-73.9918]|\n|9/1/2014 0:15:00|2014-09-01 00:15:...|40.7471|-73.6472|B02512|[40.7471,-73.6472]|\n|9/1/2014 0:16:00|2014-09-01 00:16:...|40.6613|-74.2691|B02512|[40.6613,-74.2691]|\n|9/1/2014 0:32:00|2014-09-01 00:32:...|40.3745|-73.9999|B02512|[40.3745,-73.9999]|\n|9/1/2014 0:33:00|2014-09-01 00:33:...|40.7633|-73.9773|B02512|[40.7633,-73.9773]|\n|9/1/2014 0:33:00|2014-09-01 00:33:...|40.7467|-73.6131|B02512|[40.7467,-73.6131]|\n|9/1/2014 0:37:00|2014-09-01 00:37:...|40.8105|  -73.96|B02512|  [40.8105,-73.96]|\n|9/1/2014 0:38:00|2014-09-01 00:38:...| 40.679|-74.0111|B02512| [40.679,-74.0111]|\n|9/1/2014 0:39:00|2014-09-01 00:39:...|40.4023|-73.9839|B02512|[40.4023,-73.9839]|\n|9/1/2014 0:48:00|2014-09-01 00:48:...|40.7378|-74.0395|B02512|[40.7378,-74.0395]|\n|9/1/2014 0:48:00|2014-09-01 00:48:...|40.7214|-73.9884|B02512|[40.7214,-73.9884]|\n|9/1/2014 0:49:00|2014-09-01 00:49:...|40.8646|-73.9081|B02512|[40.8646,-73.9081]|\n|9/1/2014 1:08:00|2014-09-01 01:08:...|40.7398|-74.0061|B02512|[40.7398,-74.0061]|\n|9/1/2014 1:17:00|2014-09-01 01:17:...|40.6793|-74.0116|B02512|[40.6793,-74.0116]|\n|9/1/2014 1:19:00|2014-09-01 01:19:...|40.7328|-73.9875|B02512|[40.7328,-73.9875]|\n+----------------+--------------------+-------+--------+------+------------------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558793_801693805",
      "id": "20170809-192522_955671617",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:35:07 PM",
      "dateFinished": "Aug 16, 2017 10:35:09 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// create k means object\n// set the parameters to define the number of clusters and the maximum number of iterations to determine the clusters\n// fit the model to the input data\n\nval Array(trainingData, testData) \u003d df2.randomSplit(Array(0.8, 0.2))\nval kmeans \u003d new KMeans().setK(8).setFeaturesCol(\"features\").setPredictionCol(\"prediction\")\nval model \u003d kmeans.fit(df2)\n\n// 8 clusters based on \u0027features\u0027\nprintln(\"Final Clusters: \")\nmodel.clusterCenters.foreach(println)",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:39:36 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n\ntrainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [Date/Time: string, timestamp: timestamp ... 4 more fields]\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [Date/Time: string, timestamp: timestamp ... 4 more fields]\n\nkmeans: org.apache.spark.ml.clustering.KMeans \u003d kmeans_6279cb0482ea\n\nmodel: org.apache.spark.ml.clustering.KMeansModel \u003d kmeans_6279cb0482ea\nFinal Clusters: \n[40.728105828693934,-73.99965521944587]\n[40.65556399125829,-73.78304139206466]\n[40.687278468416395,-73.96337435482819]\n[40.77336770751877,-73.86570066236195]\n[40.858524679487246,-73.59887399267402]\n[40.6972876332623,-74.20379686954863]\n[40.75740901039968,-73.97954068909587]\n[40.79351345875666,-73.9524904773385]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558795_802463302",
      "id": "20170809-192621_197690955",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:38:24 PM",
      "dateFinished": "Aug 16, 2017 10:39:33 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "  // apply the trained model on test dataset\n  \n  val categories \u003d model.transform(testData)\n  categories.show()",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:39:54 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ncategories: org.apache.spark.sql.DataFrame \u003d [Date/Time: string, timestamp: timestamp ... 5 more fields]\n+----------------+--------------------+-------+--------+------+------------------+----------+\n|       Date/Time|           timestamp|    Lat|     Lon|  Base|          features|prediction|\n+----------------+--------------------+-------+--------+------+------------------+----------+\n|9/1/2014 0:00:00|2014-09-01 00:00:...|  40.73|-73.9896|B02598|  [40.73,-73.9896]|         0|\n|9/1/2014 0:00:00|2014-09-01 00:00:...|40.8259|-73.9451|B02598|[40.8259,-73.9451]|         7|\n|9/1/2014 0:01:00|2014-09-01 00:01:...|40.6449|-73.7819|B02617|[40.6449,-73.7819]|         1|\n|9/1/2014 0:01:00|2014-09-01 00:01:...|40.7149|-73.9997|B02617|[40.7149,-73.9997]|         0|\n|9/1/2014 0:01:00|2014-09-01 00:01:...|40.7287|-74.0002|B02617|[40.7287,-74.0002]|         0|\n|9/1/2014 0:01:00|2014-09-01 00:01:...|40.7474|-74.0082|B02617|[40.7474,-74.0082]|         0|\n|9/1/2014 0:01:00|2014-09-01 00:01:...| 40.748|-73.9407|B02617| [40.748,-73.9407]|         6|\n|9/1/2014 0:03:00|2014-09-01 00:03:...| 40.717| -74.011|B02598|  [40.717,-74.011]|         0|\n|9/1/2014 0:04:00|2014-09-01 00:04:...|40.7324|-73.9859|B02617|[40.7324,-73.9859]|         0|\n|9/1/2014 0:04:00|2014-09-01 00:04:...|40.7677|-73.9808|B02617|[40.7677,-73.9808]|         6|\n|9/1/2014 0:05:00|2014-09-01 00:05:...|40.6356|-73.7311|B02617|[40.6356,-73.7311]|         1|\n|9/1/2014 0:05:00|2014-09-01 00:05:...|40.7302|-74.0049|B02617|[40.7302,-74.0049]|         0|\n|9/1/2014 0:05:00|2014-09-01 00:05:...|40.7363|-73.9506|B02617|[40.7363,-73.9506]|         6|\n|9/1/2014 0:05:00|2014-09-01 00:05:...|40.7456|-73.9898|B02598|[40.7456,-73.9898]|         6|\n|9/1/2014 0:06:00|2014-09-01 00:06:...| 40.745|-73.9889|B02512| [40.745,-73.9889]|         6|\n|9/1/2014 0:07:00|2014-09-01 00:07:...|40.7252|-74.0034|B02598|[40.7252,-74.0034]|         0|\n|9/1/2014 0:07:00|2014-09-01 00:07:...|40.7947|-73.9662|B02598|[40.7947,-73.9662]|         7|\n|9/1/2014 0:08:00|2014-09-01 00:08:...|40.7498|-73.9903|B02598|[40.7498,-73.9903]|         6|\n|9/1/2014 0:08:00|2014-09-01 00:08:...|40.7591|-73.9612|B02617|[40.7591,-73.9612]|         6|\n|9/1/2014 0:09:00|2014-09-01 00:09:...|40.7111|-74.0071|B02617|[40.7111,-74.0071]|         0|\n+----------------+--------------------+-------+--------+------+------------------+----------+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558797_800154809",
      "id": "20170809-195009_913237796",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:39:46 PM",
      "dateFinished": "Aug 16, 2017 10:39:52 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "1. Which hours of the day and which cluster had the highest number of pickups?",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1502947558798_801309056",
      "id": "20170809-213403_1100420164",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "categories.select(hour($\"timestamp\").alias(\"hour\"), $\"prediction\")\n          .groupBy(\"hour\", \"prediction\")\n          .agg(count(\"prediction\").alias(\"count\"))\n          .orderBy(desc(\"count\")).show",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:40:01 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----+----------+-----+\n|hour|prediction|count|\n+----+----------+-----+\n|  17|         6| 5832|\n|  18|         6| 5775|\n|  16|         6| 5362|\n|  18|         0| 5076|\n|  19|         0| 5023|\n|  19|         6| 4936|\n|  17|         0| 4930|\n|  15|         6| 4646|\n|  20|         0| 4602|\n|  16|         0| 4523|\n|  21|         0| 4515|\n|  20|         6| 4252|\n|  15|         0| 4135|\n|  22|         0| 4064|\n|  21|         6| 3821|\n|  14|         6| 3573|\n|  14|         0| 3524|\n|  23|         0| 3294|\n|  13|         0| 3048|\n|  13|         6| 3047|\n+----+----------+-----+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558800_811312527",
      "id": "20170809-195344_1475055524",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:40:01 PM",
      "dateFinished": "Aug 16, 2017 10:40:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "z.show(categories.select(hour($\"timestamp\").alias(\"hour\"), $\"prediction\")\n          .groupBy(\"hour\", \"prediction\")\n          .agg(count(\"prediction\").alias(\"count\"))\n          .orderBy(desc(\"count\")))",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:40:31 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "hour",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "prediction",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "count",
                  "index": 2.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "hour\tprediction\tcount\n17\t6\t5832\n18\t6\t5775\n16\t6\t5362\n18\t0\t5076\n19\t0\t5023\n19\t6\t4936\n17\t0\t4930\n15\t6\t4646\n20\t0\t4602\n16\t0\t4523\n21\t0\t4515\n20\t6\t4252\n15\t0\t4135\n22\t0\t4064\n21\t6\t3821\n14\t6\t3573\n14\t0\t3524\n23\t0\t3294\n13\t0\t3048\n13\t6\t3047\n22\t6\t2918\n8\t0\t2875\n8\t6\t2870\n7\t0\t2739\n7\t6\t2732\n12\t6\t2624\n11\t6\t2592\n12\t0\t2550\n9\t6\t2501\n10\t6\t2454\n11\t0\t2407\n10\t0\t2339\n9\t0\t2306\n0\t0\t2239\n6\t0\t1923\n23\t6\t1793\n19\t2\t1703\n6\t6\t1698\n21\t2\t1680\n18\t2\t1649\n20\t2\t1610\n1\t0\t1584\n22\t2\t1550\n7\t7\t1540\n17\t2\t1501\n8\t7\t1378\n17\t7\t1360\n16\t2\t1290\n6\t7\t1289\n15\t2\t1271\n23\t2\t1260\n16\t7\t1239\n5\t0\t1230\n18\t7\t1225\n7\t2\t1183\n14\t2\t1166\n8\t2\t1160\n13\t2\t1154\n15\t7\t1139\n19\t7\t1128\n9\t2\t1108\n14\t7\t1107\n6\t2\t1087\n10\t2\t1087\n11\t2\t1081\n0\t6\t1056\n12\t2\t1052\n2\t0\t1044\n20\t7\t1029\n21\t7\t1015\n9\t7\t1010\n13\t7\t987\n5\t6\t954\n11\t7\t918\n12\t7\t901\n10\t7\t895\n5\t2\t877\n0\t2\t870\n3\t0\t855\n4\t0\t816\n22\t7\t759\n1\t2\t643\n20\t3\t622\n1\t6\t617\n4\t6\t614\n18\t3\t614\n17\t3\t596\n5\t7\t590\n19\t3\t586\n16\t3\t581\n21\t3\t546\n4\t2\t523\n23\t7\t519\n14\t1\t499\n3\t6\t473\n15\t3\t473\n19\t1\t461\n20\t1\t460\n3\t2\t459\n14\t3\t444\n2\t6\t439\n2\t2\t430\n10\t3\t423\n16\t1\t415\n9\t3\t415\n22\t3\t395\n13\t3\t383\n22\t1\t380\n12\t3\t373\n11\t3\t372\n15\t1\t368\n21\t1\t363\n4\t7\t361\n18\t1\t356\n8\t3\t355\n7\t3\t333\n17\t1\t324\n0\t7\t323\n13\t1\t302\n23\t1\t268\n6\t3\t265\n6\t1\t262\n3\t7\t244\n5\t1\t242\n23\t3\t212\n12\t1\t202\n1\t7\t188\n11\t1\t181\n15\t5\t162\n16\t5\t158\n5\t3\t153\n21\t5\t152\n7\t1\t151\n4\t1\t151\n18\t5\t145\n13\t5\t142\n10\t1\t140\n2\t7\t133\n20\t5\t132\n9\t1\t130\n22\t5\t129\n17\t5\t126\n14\t5\t122\n19\t5\t121\n8\t1\t103\n0\t3\t99\n11\t5\t92\n0\t1\t82\n4\t3\t82\n12\t5\t81\n23\t5\t76\n3\t3\t75\n10\t5\t69\n15\t4\t68\n14\t4\t68\n17\t4\t62\n1\t3\t61\n16\t4\t61\n9\t5\t60\n18\t4\t57\n8\t5\t56\n13\t4\t55\n7\t5\t52\n22\t4\t51\n21\t4\t50\n2\t3\t47\n5\t5\t47\n8\t4\t44\n19\t4\t44\n11\t4\t43\n20\t4\t43\n10\t4\t43\n6\t5\t43\n0\t5\t43\n12\t4\t40\n4\t5\t38\n3\t1\t35\n9\t4\t32\n7\t4\t28\n5\t4\t25\n0\t4\t20\n23\t4\t20\n1\t1\t19\n1\t5\t19\n2\t1\t18\n6\t4\t14\n3\t5\t14\n1\t4\t10\n4\t4\t10\n2\t5\t8\n2\t4\t8\n3\t4\t6\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558801_810927778",
      "id": "20170809-214412_723794660",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:40:18 PM",
      "dateFinished": "Aug 16, 2017 10:40:25 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "2. How many pickups occurred in each cluster?",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1502947558802_812082025",
      "id": "20170809-212754_1567860801",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "categories.groupBy($\"prediction\")\n          .agg(count(\"prediction\").alias(\"count\"))\n          .orderBy(desc(\"count\")).show()",
      "user": "anonymous",
      "dateUpdated": "Aug 16, 2017 10:40:54 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------+-----+\n|prediction|count|\n+----------+-----+\n|         0|71641|\n|         6|67579|\n|         2|27394|\n|         7|21277|\n|         3| 8505|\n|         1| 5912|\n|         5| 2087|\n|         4|  902|\n+----------+-----+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558804_809773532",
      "id": "20170809-213722_9362091",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "dateStarted": "Aug 16, 2017 10:40:43 PM",
      "dateFinished": "Aug 16, 2017 10:40:52 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "z.show(categories.groupBy($\"prediction\")\n                 .agg(count(\"prediction\").alias(\"count\"))\n                 .orderBy(desc(\"count\")))",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "prediction",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "prediction",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "prediction\tcount\n0\t71775\n6\t68258\n2\t27463\n7\t21356\n3\t8566\n1\t5993\n5\t2008\n4\t867\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558805_809388783",
      "id": "20170809-214154_1288390825",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "3. Which base(location) has the maximum number of pickups?",
      "text": "",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1502947558806_810543029",
      "id": "20170809-214645_1113721354",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "categories.groupBy($\"Base\")\n          .agg(count(\"prediction\").alias(count))\n          .orderBy(desc(\"count\")).show()\n/*          \n// Plot      \nz.show(categories.groupBy($\"Base\")\n          .agg(count(\"prediction\").alias(\"count\"))\n          .orderBy(desc(\"count\")))\n*/",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {
          "1": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": true,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Base",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [
                {
                  "name": "Base",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": "count",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------+-----+\n|  Base|count|\n+------+-----+\n|B02617|75479|\n|B02598|48164|\n|B02682|39201|\n|B02764|35728|\n|B02512| 6886|\n+------+-----+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558807_810158280",
      "id": "20170810-152226_172644850",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "4. Which weekday has the maximum number of pickups?",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1502947558808_808234536",
      "id": "20170810-152558_1556075856",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "categories.groupBy(weekofyear($\"timestamp\").alias(\"weekday\"))\n          .agg(count(\"prediction\").alias(\"count\"))\n          .orderBy(desc(\"count\")).show()",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+-----+\n|weekday|count|\n+-------+-----+\n|     38|49937|\n|     37|49542|\n|     39|46740|\n|     36|46566|\n|     40|12673|\n+-------+-----+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558809_807849787",
      "id": "20170810-160215_24970888",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "case class Map( lat : Float, lon : Float)",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\ndefined class Map\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558813_806310791",
      "id": "20170810-160306_1539905399",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.commons.io.IOUtils\nimport java.net.URL\nimport java.nio.charset.Charset\nimport org.apache.spark.mllib.linalg.Vector\n\nval myMapRDD \u003d sc.parallelize(model.clusterCenters).map(s \u003d\u003e Map(s(0).toFloat, s(1).toFloat))",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nimport org.apache.commons.io.IOUtils\n\nimport java.net.URL\n\nimport java.nio.charset.Charset\n\nimport org.apache.spark.mllib.linalg.Vector\n\nmyMapRDD: org.apache.spark.rdd.RDD[Map] \u003d MapPartitionsRDD[420] at map at \u003cconsole\u003e:222\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558815_807080289",
      "id": "20170810-173908_1312888204",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\nval myMapDF \u003d myMapRDD.toDF()\nmyMapDF.show()",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nmyMapDF: org.apache.spark.sql.DataFrame \u003d [lat: float, lon: float]\n+---------+---------+\n|      lat|      lon|\n+---------+---------+\n|40.728107|-73.99966|\n|40.655563|-73.78304|\n| 40.68728|-73.96337|\n| 40.77337| -73.8657|\n|40.858524|-73.59888|\n| 40.69729| -74.2038|\n| 40.75741|-73.97954|\n|40.793514|-73.95249|\n+---------+---------+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558816_792844580",
      "id": "20170810-180614_1077289765",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "myMapDF.createOrReplaceTempView(\"ClusterMap\")",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1502947558818_793614078",
      "id": "20170810-175454_1257313350",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\n\nselect * from ClusterMap",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/text",
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": true
            },
            "helium": {}
          }
        },
        "enabled": true,
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "lat\tlon\n40.728107\t-73.99966\n40.655563\t-73.78304\n40.68728\t-73.96337\n40.77337\t-73.8657\n40.858524\t-73.59888\n40.69729\t-74.2038\n40.75741\t-73.97954\n40.793514\t-73.95249\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1502947558819_793229329",
      "id": "20170810-230704_405721236",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%angular\n",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1502947558821_790920835",
      "id": "20170811-000059_1548009616",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\n",
      "dateUpdated": "Aug 16, 2017 10:25:58 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/undefined",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "editOnDblClick": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1502947558822_792075082",
      "id": "20170811-001953_1845565781",
      "dateCreated": "Aug 16, 2017 10:25:58 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Clustering using Spark MLlib- Uber data",
  "id": "2CPWGEYQV",
  "angularObjects": {
    "2CPJ3QQS3:shared_process": [],
    "2CQ3S9HXD:shared_process": [],
    "2CP38XEE1:shared_process": [],
    "2CR4FAJ3K:shared_process": [],
    "2CRKKWAUN:shared_process": [],
    "2CNWX8NRS:shared_process": [],
    "2CPXTNX5C:shared_process": [],
    "2CPSM3TXG:shared_process": [],
    "2CPR5WWTB:shared_process": [],
    "2CR74YFC6:shared_process": [],
    "2CSBECX5Q:shared_process": [],
    "2CRDJS65D:shared_process": [],
    "2CPVTQEZJ:shared_process": [],
    "2CQ2MRVY1:shared_process": [],
    "2CRA42DNP:shared_process": [],
    "2CP62B91C:shared_process": [],
    "2CPBK8F2A:shared_process": [],
    "2CPU3V8PF:shared_process": [],
    "2CQPR1QSH:shared_process": []
  },
  "config": {},
  "info": {}
}